{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the SpaceONE developer guides. The documents list in the left navigation teach you how to build SpaceONE. The Achitecture design describes the software architecture of SpaceONE. The Core team developed new Python application framework for micro service architecture. The Console Framework introduces ATOMIC design pattern with Vue.js. The Plugins shows how SpaceONE can easily extend service coverage by developing various plugins. If you want to develop core system, jump into Core development . Start with building from scratch. The Console development section will guide you how to develop web console page. The Plugins development section describes how to develop new plugin. You can easily build and test your own plugin with a few steps. Design Your SpaceONE!","title":"Home"},{"location":"api/","text":"[SpaceONE API] https://spaceone-dev.gitbook.io/spaceone-apis/","title":"API References"},{"location":"introduction/","text":"SpaceONE is an open-source Cloud Management Platform that leverages existing multi cloud and on-premise IDCs. Single Sourch of Truth Intent-based Infrastructure Self-Service Open Platform Easy Expansion Enterprise-Level","title":"Introduction"},{"location":"api/getting-started/","text":"Developer Guideline This guide explains the new API spec which extends the spaceone-api . git clone https://github.com/spaceone-dev/api.git 1. Create new API spec file # Create new API spec file for new micro service. The file location must be proto/spaceone/api/<new service name>/<version>/<API spec file> For example, the APIs in inventory service is defined at proto \u2514\u2500\u2500 spaceone \u2514\u2500\u2500 api \u251c\u2500\u2500 core \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 handler.proto \u2502 \u251c\u2500\u2500 plugin.proto \u2502 \u251c\u2500\u2500 query.proto \u2502 \u2514\u2500\u2500 server_info.proto \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 plugin \u2502 \u2502 \u2514\u2500\u2500 collector.proto \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 cloud_service.proto \u2502 \u251c\u2500\u2500 cloud_service_type.proto \u2502 \u251c\u2500\u2500 collector.proto \u2502 \u251c\u2500\u2500 job.proto \u2502 \u251c\u2500\u2500 job_task.proto \u2502 \u251c\u2500\u2500 region.proto \u2502 \u251c\u2500\u2500 server.proto \u2502 \u2514\u2500\u2500 task_item.proto \u2514\u2500\u2500 sample \u2514\u2500\u2500 v1 \u2514\u2500\u2500 helloworld.proto If you create new micro service called sample, create a directory proto/spaceone/api/sample/v1 2. Define API # After creating API spec file, update gRPC protobuf. The content consists with two sections. + service + messages service defines the RPC method and message defines the request and response data structure. syntax = \"proto3\"; package spaceone.api.sample.v1; // desc: The greeting service definition. service HelloWorld { // desc: Sends a greeting rpc say_hello (HelloRequest) returns (HelloReply) {} } // desc: The request message containing the user's name. message HelloRequest { // is_required: true string name = 1; } // desc: The response message containing the greetings message HelloReply { string message = 1; } 3. Build API spec to specific language. # Protobuf can not be used directly, it must be translated to target langauge like python or Go. If you create new micro service directory, udpate Makefile Append directory name at TARGET TARGET = core identity repository plugin secret inventory monitoring statistics config report sample Currently API supports python output. make python The generated python output is located at dist/python directory. dist \u2514\u2500\u2500 python \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 spaceone \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 api \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 core \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 handler_pb2.py \u2502 \u251c\u2500\u2500 handler_pb2_grpc.py \u2502 \u251c\u2500\u2500 plugin_pb2.py \u2502 \u251c\u2500\u2500 plugin_pb2_grpc.py \u2502 \u251c\u2500\u2500 query_pb2.py \u2502 \u251c\u2500\u2500 query_pb2_grpc.py \u2502 \u251c\u2500\u2500 server_info_pb2.py \u2502 \u2514\u2500\u2500 server_info_pb2_grpc.py \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 plugin \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 collector_pb2.py \u2502 \u2502 \u2514\u2500\u2500 collector_pb2_grpc.py \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 cloud_service_pb2.py \u2502 \u251c\u2500\u2500 cloud_service_pb2_grpc.py \u2502 \u251c\u2500\u2500 cloud_service_type_pb2.py \u2502 \u251c\u2500\u2500 cloud_service_type_pb2_grpc.py \u2502 \u251c\u2500\u2500 collector_pb2.py \u2502 \u251c\u2500\u2500 collector_pb2_grpc.py \u2502 \u251c\u2500\u2500 job_pb2.py \u2502 \u251c\u2500\u2500 job_pb2_grpc.py \u2502 \u251c\u2500\u2500 job_task_pb2.py \u2502 \u251c\u2500\u2500 job_task_pb2_grpc.py \u2502 \u251c\u2500\u2500 region_pb2.py \u2502 \u251c\u2500\u2500 region_pb2_grpc.py \u2502 \u251c\u2500\u2500 server_pb2.py \u2502 \u251c\u2500\u2500 server_pb2_grpc.py \u2502 \u251c\u2500\u2500 task_item_pb2.py \u2502 \u2514\u2500\u2500 task_item_pb2_grpc.py \u2514\u2500\u2500 sample \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 v1 \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 helloworld_pb2.py \u2514\u2500\u2500 helloworld_pb2_grpc.py 4. References # Google Protobuf https://developers.google.com/protocol-buffers/docs/proto3","title":"Getting Started"},{"location":"api/getting-started/#1-create-new-api-spec-file","text":"Create new API spec file for new micro service. The file location must be proto/spaceone/api/<new service name>/<version>/<API spec file> For example, the APIs in inventory service is defined at proto \u2514\u2500\u2500 spaceone \u2514\u2500\u2500 api \u251c\u2500\u2500 core \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 handler.proto \u2502 \u251c\u2500\u2500 plugin.proto \u2502 \u251c\u2500\u2500 query.proto \u2502 \u2514\u2500\u2500 server_info.proto \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 plugin \u2502 \u2502 \u2514\u2500\u2500 collector.proto \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 cloud_service.proto \u2502 \u251c\u2500\u2500 cloud_service_type.proto \u2502 \u251c\u2500\u2500 collector.proto \u2502 \u251c\u2500\u2500 job.proto \u2502 \u251c\u2500\u2500 job_task.proto \u2502 \u251c\u2500\u2500 region.proto \u2502 \u251c\u2500\u2500 server.proto \u2502 \u2514\u2500\u2500 task_item.proto \u2514\u2500\u2500 sample \u2514\u2500\u2500 v1 \u2514\u2500\u2500 helloworld.proto If you create new micro service called sample, create a directory proto/spaceone/api/sample/v1","title":"1. Create new API spec file"},{"location":"api/getting-started/#2-define-api","text":"After creating API spec file, update gRPC protobuf. The content consists with two sections. + service + messages service defines the RPC method and message defines the request and response data structure. syntax = \"proto3\"; package spaceone.api.sample.v1; // desc: The greeting service definition. service HelloWorld { // desc: Sends a greeting rpc say_hello (HelloRequest) returns (HelloReply) {} } // desc: The request message containing the user's name. message HelloRequest { // is_required: true string name = 1; } // desc: The response message containing the greetings message HelloReply { string message = 1; }","title":"2. Define API"},{"location":"api/getting-started/#3-build-api-spec-to-specific-language","text":"Protobuf can not be used directly, it must be translated to target langauge like python or Go. If you create new micro service directory, udpate Makefile Append directory name at TARGET TARGET = core identity repository plugin secret inventory monitoring statistics config report sample Currently API supports python output. make python The generated python output is located at dist/python directory. dist \u2514\u2500\u2500 python \u251c\u2500\u2500 setup.py \u2514\u2500\u2500 spaceone \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 api \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 core \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 handler_pb2.py \u2502 \u251c\u2500\u2500 handler_pb2_grpc.py \u2502 \u251c\u2500\u2500 plugin_pb2.py \u2502 \u251c\u2500\u2500 plugin_pb2_grpc.py \u2502 \u251c\u2500\u2500 query_pb2.py \u2502 \u251c\u2500\u2500 query_pb2_grpc.py \u2502 \u251c\u2500\u2500 server_info_pb2.py \u2502 \u2514\u2500\u2500 server_info_pb2_grpc.py \u251c\u2500\u2500 inventory \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 plugin \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u251c\u2500\u2500 collector_pb2.py \u2502 \u2502 \u2514\u2500\u2500 collector_pb2_grpc.py \u2502 \u2514\u2500\u2500 v1 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 cloud_service_pb2.py \u2502 \u251c\u2500\u2500 cloud_service_pb2_grpc.py \u2502 \u251c\u2500\u2500 cloud_service_type_pb2.py \u2502 \u251c\u2500\u2500 cloud_service_type_pb2_grpc.py \u2502 \u251c\u2500\u2500 collector_pb2.py \u2502 \u251c\u2500\u2500 collector_pb2_grpc.py \u2502 \u251c\u2500\u2500 job_pb2.py \u2502 \u251c\u2500\u2500 job_pb2_grpc.py \u2502 \u251c\u2500\u2500 job_task_pb2.py \u2502 \u251c\u2500\u2500 job_task_pb2_grpc.py \u2502 \u251c\u2500\u2500 region_pb2.py \u2502 \u251c\u2500\u2500 region_pb2_grpc.py \u2502 \u251c\u2500\u2500 server_pb2.py \u2502 \u251c\u2500\u2500 server_pb2_grpc.py \u2502 \u251c\u2500\u2500 task_item_pb2.py \u2502 \u2514\u2500\u2500 task_item_pb2_grpc.py \u2514\u2500\u2500 sample \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 v1 \u251c\u2500\u2500 __init__.py \u251c\u2500\u2500 helloworld_pb2.py \u2514\u2500\u2500 helloworld_pb2_grpc.py","title":"3. Build API spec to specific language."},{"location":"api/getting-started/#4-references","text":"Google Protobuf https://developers.google.com/protocol-buffers/docs/proto3","title":"4. References"},{"location":"architecture/console-framework/","text":"Console Framework # Console is developed with Vue.js and Node.js","title":"Console Framework"},{"location":"architecture/console-framework/#console-framework","text":"Console is developed with Vue.js and Node.js","title":"Console Framework"},{"location":"architecture/msa-framework/","text":"The Core team of SpaceONE has developed new Python application framework focusing on safe, speed, simplicity, and productivity. The application can be easily served as gRPC server, RESTful server, scheduler or worker.","title":"MSA Framework"},{"location":"architecture/plugins/","text":"Plugins Architecture #","title":"Plugins"},{"location":"architecture/plugins/#plugins-architecture","text":"","title":"Plugins Architecture"},{"location":"console/coding-style/","text":"","title":"Coding Style"},{"location":"console/getting-started/","text":"","title":"Getting Started"},{"location":"core/coding-style/","text":"","title":"Coding Style"},{"location":"core/getting-started/","text":"Development workflow 1. Fork in the cloud # Visit https://github.com/spaceone-dev There are lots of repositories. spaceone is top repository. Each micro service has own repository like identity , or inventory . Click 'Fork' button (top right) to establish a cloud-based fork. 2. Clone fork to local storage # Create your clone: git clone https://github.com/$user/spaceone.git cd spaceone 3. Branch # Add upstream: git remote add upstream https://github.com/spaceone-dev/spaceone.git # Never push to upstream master git remote set-url --push upstream no_push # Confirm that your remotes make sense: git remote -v Get your local master up to date: git fetch upstream git checkout master git rebase upstream/master Branch from it: git checkout -b myfeature 5. Commit # Commit your changes. git add <changed files> git commit -s Likely you go back and edit/build/test some more then 'commit --amend' in a few cycles. 6. Push # When ready to review (or just to establish an offsite backup of your work), push your branch to your fork on github.com : git push -f origin myfeature 7. Create a pull request # Visit your fork at https://github.com/$user/spaceone Click the Crete pull request button","title":"Getting Started"},{"location":"core/getting-started/#1-fork-in-the-cloud","text":"Visit https://github.com/spaceone-dev There are lots of repositories. spaceone is top repository. Each micro service has own repository like identity , or inventory . Click 'Fork' button (top right) to establish a cloud-based fork.","title":"1. Fork in the cloud"},{"location":"core/getting-started/#2-clone-fork-to-local-storage","text":"Create your clone: git clone https://github.com/$user/spaceone.git cd spaceone","title":"2. Clone fork to local storage"},{"location":"core/getting-started/#3-branch","text":"Add upstream: git remote add upstream https://github.com/spaceone-dev/spaceone.git # Never push to upstream master git remote set-url --push upstream no_push # Confirm that your remotes make sense: git remote -v Get your local master up to date: git fetch upstream git checkout master git rebase upstream/master Branch from it: git checkout -b myfeature","title":"3. Branch"},{"location":"core/getting-started/#5-commit","text":"Commit your changes. git add <changed files> git commit -s Likely you go back and edit/build/test some more then 'commit --amend' in a few cycles.","title":"5. Commit"},{"location":"core/getting-started/#6-push","text":"When ready to review (or just to establish an offsite backup of your work), push your branch to your fork on github.com : git push -f origin myfeature","title":"6. Push"},{"location":"core/getting-started/#7-create-a-pull-request","text":"Visit your fork at https://github.com/$user/spaceone Click the Crete pull request button","title":"7. Create a pull request"},{"location":"core/scheduler_and_worker/","text":"Scheduler and Worker Development Pattern 1. Architecture # The Scheduler and Worker are two separated micro-services which communicates each other via queue. Scheduler specifies task(a.k.a. SpaceONE Pipeline Template) then push task to queue. Worker gets task from queue then execute task. 2. Example configuration # Scheduler configuration # The Scheduler needs queue and scheduler function which create scheduling task. This is inventory-scheduler configuration. QUEUES: collector_q: backend: spaceone.core.queue.redis_queue.RedisQueue host: redis port: 6379 channel: collector SCHEDULERS: hourly_scheduler: backend: spaceone.inventory.scheduler.inventory_scheduler.InventoryHourlyScheduler queue: collector_q interval: 1 minute: ':01' TOKEN: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVC.... Worker configuration # The Worker needs queue and worker function which executes scheduling task. This is inventory-worker configuration. QUEUES: collector_q: backend: spaceone.core.queue.redis_queue.RedisQueue host: redis port: 6379 channel: collector WORKERS: collector_worker: backend: spaceone.core.scheduler.worker.BaseWorker queue: collector_q pool: 1 3. Start Scheduler or Worker # Base on configuration, server can be scheduler or worker. The commandline for Scheduler or Worker is same. spaceone scheduler <service name> For example, inventory Worker is started by spaceone scheduler spaceone.inventory -c /opt/inventory.yml . You can start Scheduler and Worker together, if your configuration includes QUEUES, SCHEDULERS and WORKERS . 4. Scheduler Development # Scheduler Class # Scheduler class is defined at spaceone/core/schduler/scheduler.py at python-core repository. If you want to create new scheduler, inherit BaseScheduler class. Each implemented class should implement create_task() . The create_task() function is automatically called in-time which is specified at Scheduler configuration. For example, if you inherit HourlyScheduler, the create_task is called in every N hours. If you inherit IntervalScheduler, the create_task is called in every N seconds. Example: InventoryHourlyScheduler # InventoryHourlyScheduler is called at every 01 minutes like from 00:01, 01:01 to 23:01. The create_task() should create list of STP(SpaceONE Template Pipeline). file: /src/spaceone/inventory/scheduler/inventory_scheduler.py def create_task(self): schedules = self.list_schedules() result = [] for schedule in schedules: stp = self._create_job_request(schedule) result.append(stp) return result 4. SpaceONE Template Pipeline # You have to specify task based one STP(SpaceONE Tempalte Pipeline). The single STP has following rule: { \"name\": Pipeline Name, \"version\": \"v1\", \"executionEngine\": \"BaseWorker\", \"stages\": [ { \"locator\": \"SERVICE\" | \"MANAGER\" | \"CONNECTOR\", # Calling Object \"name\" : \"XXXXService\", # Calling Object name \"metadata\" : {Metadata(dict)}, # Metadata, Service Call needs metadata \"method\": Method name, # method name \"params\": { Real Parameter } # parameter }, { ... } ] } For example, if you want to call collect API in inventory, the STP has { \"name\": \"Inventory Collect\", \"version\": \"v1\", \"executionEngine\": \"BaseWorker\", \"stages\": [ { \"locator\": \"SERVICE\", \"name\" : \"CollectorService\", \"metadata\": {'token': 'xxxxxx', 'user_id': 'yyyyy'}, \"method\": \"collect\", \"params\": {'params': { 'collector_id': 'xxxxx', 'collector_mode': 'ALL', 'filter': {}, 'domain_id': 'dom-xxxx' } } } ] } 5. Worker Development # BaseWorker is just executing STP. For example, if inventory-worker get Inventory Collect task from Queue. It execute method based on specification.","title":"Scheduler & Worker"},{"location":"core/scheduler_and_worker/#1-architecture","text":"The Scheduler and Worker are two separated micro-services which communicates each other via queue. Scheduler specifies task(a.k.a. SpaceONE Pipeline Template) then push task to queue. Worker gets task from queue then execute task.","title":"1. Architecture"},{"location":"core/scheduler_and_worker/#2-example-configuration","text":"","title":"2. Example configuration"},{"location":"core/scheduler_and_worker/#scheduler-configuration","text":"The Scheduler needs queue and scheduler function which create scheduling task. This is inventory-scheduler configuration. QUEUES: collector_q: backend: spaceone.core.queue.redis_queue.RedisQueue host: redis port: 6379 channel: collector SCHEDULERS: hourly_scheduler: backend: spaceone.inventory.scheduler.inventory_scheduler.InventoryHourlyScheduler queue: collector_q interval: 1 minute: ':01' TOKEN: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVC....","title":"Scheduler configuration"},{"location":"core/scheduler_and_worker/#worker-configuration","text":"The Worker needs queue and worker function which executes scheduling task. This is inventory-worker configuration. QUEUES: collector_q: backend: spaceone.core.queue.redis_queue.RedisQueue host: redis port: 6379 channel: collector WORKERS: collector_worker: backend: spaceone.core.scheduler.worker.BaseWorker queue: collector_q pool: 1","title":"Worker configuration"},{"location":"core/scheduler_and_worker/#3-start-scheduler-or-worker","text":"Base on configuration, server can be scheduler or worker. The commandline for Scheduler or Worker is same. spaceone scheduler <service name> For example, inventory Worker is started by spaceone scheduler spaceone.inventory -c /opt/inventory.yml . You can start Scheduler and Worker together, if your configuration includes QUEUES, SCHEDULERS and WORKERS .","title":"3. Start Scheduler or Worker"},{"location":"core/scheduler_and_worker/#4-scheduler-development","text":"","title":"4. Scheduler Development"},{"location":"core/scheduler_and_worker/#scheduler-class","text":"Scheduler class is defined at spaceone/core/schduler/scheduler.py at python-core repository. If you want to create new scheduler, inherit BaseScheduler class. Each implemented class should implement create_task() . The create_task() function is automatically called in-time which is specified at Scheduler configuration. For example, if you inherit HourlyScheduler, the create_task is called in every N hours. If you inherit IntervalScheduler, the create_task is called in every N seconds.","title":"Scheduler Class"},{"location":"core/scheduler_and_worker/#example-inventoryhourlyscheduler","text":"InventoryHourlyScheduler is called at every 01 minutes like from 00:01, 01:01 to 23:01. The create_task() should create list of STP(SpaceONE Template Pipeline). file: /src/spaceone/inventory/scheduler/inventory_scheduler.py def create_task(self): schedules = self.list_schedules() result = [] for schedule in schedules: stp = self._create_job_request(schedule) result.append(stp) return result","title":"Example: InventoryHourlyScheduler"},{"location":"core/scheduler_and_worker/#4-spaceone-template-pipeline","text":"You have to specify task based one STP(SpaceONE Tempalte Pipeline). The single STP has following rule: { \"name\": Pipeline Name, \"version\": \"v1\", \"executionEngine\": \"BaseWorker\", \"stages\": [ { \"locator\": \"SERVICE\" | \"MANAGER\" | \"CONNECTOR\", # Calling Object \"name\" : \"XXXXService\", # Calling Object name \"metadata\" : {Metadata(dict)}, # Metadata, Service Call needs metadata \"method\": Method name, # method name \"params\": { Real Parameter } # parameter }, { ... } ] } For example, if you want to call collect API in inventory, the STP has { \"name\": \"Inventory Collect\", \"version\": \"v1\", \"executionEngine\": \"BaseWorker\", \"stages\": [ { \"locator\": \"SERVICE\", \"name\" : \"CollectorService\", \"metadata\": {'token': 'xxxxxx', 'user_id': 'yyyyy'}, \"method\": \"collect\", \"params\": {'params': { 'collector_id': 'xxxxx', 'collector_mode': 'ALL', 'filter': {}, 'domain_id': 'dom-xxxx' } } } ] }","title":"4. SpaceONE Template Pipeline"},{"location":"core/scheduler_and_worker/#5-worker-development","text":"BaseWorker is just executing STP. For example, if inventory-worker get Inventory Collect task from Queue. It execute method based on specification.","title":"5. Worker Development"},{"location":"installation/docker-compose/","text":"SpaceONE Docker-Compose Installer a SpaceONE docker-compose to deploy SpaceONE on Docker. Manage your infrastructure with SpaceONE. It doesn't matter what your infrastructure is based on. SpaceONE supports AWS, GCP, Azure, IDC, ...etc. Installation # This installation is for developer only. Requirements # docker docker-compose Commands # mkdir spaceone cd spaceone git clone https://github.com/spaceone-dev/spaceone-dockercompose.git cd spaceone-dockercompose Base on your deploy environment, You should update environment variables at build-data/environment/debug.mk Especially SUPERVISOR_HOSTNAME is important. This value is configured at supervisor micro-service. ############################ # Docker Image Registry ############################# IMAGE_REGISTRY=spaceone VERSION=latest ############################ # Update Your environment # - supervisor (private ip address of this machine) # MacOS #SUPERVISOR_HOSTNAME=$(shell ipconfig getifaddr en0) # Linux SUPERVISOR_HOSTNAME=$(shell hostname -i) ############################ # Service List ############################ BACKEND = identity secret repository inventory inventory-scheduler inventory-worker plugin statistics monitoring FRONTEND = console console-api SUPERVISOR = supervisor TESTER = tester ############################ # Running List ############################ RUN_MONGODB = y RUN_REDIS = y RUN_VAULT = y RUN_CONSUL = y RUN_BACKEND = y RUN_FRONTEND = y RUN_SUPERVISOR = y RUN_TESTER = y In the repository root directory, install SpaceONE. $ make all 1. Update DNS for web browser access. # edit your hosts file for access. In Linux PC or MacOS, edit /etc/hosts In Windows PC, edit c:\\windows\\system32\\drivers\\etc\\hosts # # Elastic IP address, if you installed at EC2 instance. # <EC2 EIP> root # If you use MacOS, use 127.0.0.1 127.0.0.1 root You can see the console page via http://root:8280 Development guides # This will be appended soon. Configurations # This will be appended soon. Release History # 0.1.0 Initial version. Contributing # Fork it (https://github.com/spaceone/spaceone-dockercompose) Create your branch ( git checkout -b foo ) Commit your changes Push to your branch Create a new Pull Request (https://github.com/spaceone/spaceone-dockercompose)","title":"DockerCompose"},{"location":"installation/docker-compose/#installation","text":"This installation is for developer only.","title":"Installation"},{"location":"installation/docker-compose/#requirements","text":"docker docker-compose","title":"Requirements"},{"location":"installation/docker-compose/#commands","text":"mkdir spaceone cd spaceone git clone https://github.com/spaceone-dev/spaceone-dockercompose.git cd spaceone-dockercompose Base on your deploy environment, You should update environment variables at build-data/environment/debug.mk Especially SUPERVISOR_HOSTNAME is important. This value is configured at supervisor micro-service. ############################ # Docker Image Registry ############################# IMAGE_REGISTRY=spaceone VERSION=latest ############################ # Update Your environment # - supervisor (private ip address of this machine) # MacOS #SUPERVISOR_HOSTNAME=$(shell ipconfig getifaddr en0) # Linux SUPERVISOR_HOSTNAME=$(shell hostname -i) ############################ # Service List ############################ BACKEND = identity secret repository inventory inventory-scheduler inventory-worker plugin statistics monitoring FRONTEND = console console-api SUPERVISOR = supervisor TESTER = tester ############################ # Running List ############################ RUN_MONGODB = y RUN_REDIS = y RUN_VAULT = y RUN_CONSUL = y RUN_BACKEND = y RUN_FRONTEND = y RUN_SUPERVISOR = y RUN_TESTER = y In the repository root directory, install SpaceONE. $ make all","title":"Commands"},{"location":"installation/docker-compose/#1-update-dns-for-web-browser-access","text":"edit your hosts file for access. In Linux PC or MacOS, edit /etc/hosts In Windows PC, edit c:\\windows\\system32\\drivers\\etc\\hosts # # Elastic IP address, if you installed at EC2 instance. # <EC2 EIP> root # If you use MacOS, use 127.0.0.1 127.0.0.1 root You can see the console page via http://root:8280","title":"1. Update DNS for web browser access."},{"location":"installation/docker-compose/#development-guides","text":"This will be appended soon.","title":"Development guides"},{"location":"installation/docker-compose/#configurations","text":"This will be appended soon.","title":"Configurations"},{"location":"installation/docker-compose/#release-history","text":"0.1.0 Initial version.","title":"Release History"},{"location":"installation/docker-compose/#contributing","text":"Fork it (https://github.com/spaceone/spaceone-dockercompose) Create your branch ( git checkout -b foo ) Commit your changes Push to your branch Create a new Pull Request (https://github.com/spaceone/spaceone-dockercompose)","title":"Contributing"},{"location":"plugins/coding-style/","text":"","title":"Coding Style"},{"location":"plugins/getting-started/","text":"Developer Guideline SpaceONE plugins help users collecting data from diverse cloud services: AWS, GCP, MS Azure, etc. Developers can edit codes and even create new plugin. Initial Setting # 1. python3.x # Python 2.7.10 version is installed on MAC OS by default. You should install Python 3.x version. Mac Using Homebrew brew install python3 Windows https://www.python.org/downloads/windows/ 2. virtualenv # pip3 install virtualenv virtualenvwrapper or you can use this too: python3 -m pip install virtualenv virtualenvwrapper Edit the plugin # 1. Clone # First, go to SpaceONE(https://github.com/spaceone-dev) and choose plugin repository you want to edit. Names of plugin repositories start with **'plugin-' Click the 'Fork' button. And clone your forked repository to local. 2. Project Setting # Check the directory. plugin-***-**** \u251c\u2500\u2500 bin \u251c\u2500\u2500 pkg \u251c\u2500\u2500 src \u2514\u2500\u2500 test And go to Run > Edit Configuration. Click '+' button on the left side. Choose Python to add new configuration, and set 'Module name' as you want. Put grpc spaceone.inventory in Parameters for networking with other MicroServices. Set Python interpreter to Python 3.x you already installed. Put this on terminal.(~/plugin- - *) virtualenv -p python3.8 venv Check venv directory was created.","title":"Getting Started"},{"location":"plugins/getting-started/#initial-setting","text":"","title":"Initial Setting"},{"location":"plugins/getting-started/#1-python3x","text":"Python 2.7.10 version is installed on MAC OS by default. You should install Python 3.x version. Mac Using Homebrew brew install python3 Windows https://www.python.org/downloads/windows/","title":"1. python3.x"},{"location":"plugins/getting-started/#2-virtualenv","text":"pip3 install virtualenv virtualenvwrapper or you can use this too: python3 -m pip install virtualenv virtualenvwrapper","title":"2. virtualenv"},{"location":"plugins/getting-started/#edit-the-plugin","text":"","title":"Edit the plugin"},{"location":"plugins/getting-started/#1-clone","text":"First, go to SpaceONE(https://github.com/spaceone-dev) and choose plugin repository you want to edit. Names of plugin repositories start with **'plugin-' Click the 'Fork' button. And clone your forked repository to local.","title":"1. Clone"},{"location":"plugins/getting-started/#2-project-setting","text":"Check the directory. plugin-***-**** \u251c\u2500\u2500 bin \u251c\u2500\u2500 pkg \u251c\u2500\u2500 src \u2514\u2500\u2500 test And go to Run > Edit Configuration. Click '+' button on the left side. Choose Python to add new configuration, and set 'Module name' as you want. Put grpc spaceone.inventory in Parameters for networking with other MicroServices. Set Python interpreter to Python 3.x you already installed. Put this on terminal.(~/plugin- - *) virtualenv -p python3.8 venv Check venv directory was created.","title":"2. Project Setting"}]}